---
layout: post
title: "Hadoop安装及其配置（完全分布式）"
description: ""
category: 
tags: [Linux, Centos, Java, Hadoop]
---

## 完全分布式
*安装及其配置必须是在普通用户下进行*

### 安装
- 上传

    使用secureCRT的sftp功能上传至普通用户家目录
- 解压
>   `$ tar -xvzf hadoop-2.9.2.tar.gz`   得到 hadoop-2.9.2目录
	
- 配置环境变量
>	`$ vi /etc/profile`
```
export JAVA_HOME=/home/hadoop/jdk1.8.0_221
export HADOOP_HOME=/home/hadoop/hadoop-2.9.2					（新增）
export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin		（修改）
```

- 验证
>	`$ hadoop version`

### 配置(根据集群规划)：
- `hadoop-env.sh`
>	`$ vi /hadoop-2.9.2/etc/hadoop/hadoop-env.sh`

-   修改JAVA_HOME变量值
```$xslt
# The java implementation to use.
export JAVA_HOME=/home/hadoop/jdk1.8.0_221	(修改)
```

- `core-site.xml`
>	`$ vi core-site.xml `
	主节点
```$xslt
    <property>
		<name>fs.defaultFS</name>
		<value>hdfs://hadoop1:9000</value>
	</property>
	<property>
		<name>hadoop.tmp.dir</name>
		<value>/home/hadoop/hadoopdata</value>
	</property>
```
- `hdfs-site.xml`
>   `$ vi hdfs-site.xml`
	
```
<property>
      <name>dfs.namenode.name.dir</name>
      <value>/home/hadoop/data/hadoopdata/name</value>
      <description>为了保证元数据的安全一般配置多个不同的目录</description>
    </property>
    <property>
      <name>dfs.datanode.data.dir</name>
      <value>/home/hadoop/data/hadoopdata/data</value>
      <description>datanode的数据存储目录 </description>
    </property>
    <property>
      <name>dfs.replication</name>
      <value>2</value>
      <description>HDFS 的数据库的副本存储个数 </description>
    </property>
    <property>
      <name>dfs.secondary.http.address</name>
      <value>hadoop2:50090</value>
      <description>secondarynamenode 运行节点的信息，和 namenode 不同节点 </description>
    </property>
```
- `yarn-site.xml`
>   `$ vi yarn-site.xml`
 ```$xslt
  <property>
  	<name>yarn.resourcemanager.hostname</name>
  	<value>hadoop3</value>
  </property>
  <property>
  	<name>yarn.nodemanager.aux-services</name>
  	<value>mapreduce_shuffle</value>
  	<description>YARN 集群为MapReduce程序提供shuffle服务 </description>
  <property>
```
- `mapred-site.xml`
	从副本中复制一份xml文件
> 	$ cp mapred-site.xml.template mapred-site.xml
> 	$ vi mapred-site.xml
  
```$xslt
  <property>
    <name>mapreduce.framework.name</name>
    <value>yarn</value>
  </property>
```

- `slaves` 配置从节点的信息
>   `$ vi slaves`
```$xslt
hadoop1
hadoop2
hadoop3
```

- 远程发送至其他节点

>	`$ scp -r hadoop-2.9.2 hadoop@hadoop2:$PWD`

>	`$ scp -r hadoop-2.9.2 hadoop@hadoop3:$PWD`

>	`$ sudo scp -r /etc/profile root@hadoop2:/etc`

>	`$ sudo scp -r /etc/profile root@hadoop3:/etc`

>	`$ source /etc/profile`

- 进行格式化

>	`$ hadoop namenode -formate` 必须在namenode节点执行

- 启动

>	启动HDFS		 `$ start-dfs.sh `

>	启动yarn		 `$ start-yarn.sh`

jps命令查看
	网页： 
		HDFS:  
		YARN: hadoop3:8088

### 集群规划
```$xslt
                hdfs										yarn
hadoop1		namenode	datanode												nodemanager
hadoop2 				datanode	secondarynamenode							nodemanager
hadoop3					datanode							resourcemanager		nodemanager
```

普通用户执行系统命令当操作不了的时候 使用sudo


### 单独启动：
	HDFS:
		$ hadoop-daemon.sh start hdfs
		$ hadoop-daemon.sh start namenode
		$ hadoop-daemon.sh start resourcemanager

	YARN:
		$ yarn-daemon.sh start yarn
		$ yarn-daemon.sh start resourcemanager

搭建过程注意事项：

    1） 集群的成功的格式化智能格式化一次，不成功的格式化一致修改，并格式化到成功，成功后，再次执行需要删除 namenode的数据和 datanode的数据。
		因为里面有版本信息，重新格式化会重新生成集群版本信息




{% include JB/setup %}
